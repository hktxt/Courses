{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Dl8oeOFx0eg3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "fCkDJTUM0ghB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d375ae0c-a036-4865-902e-af4a423b7c10"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-03-08 05:41:58--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-08 05:42:03 (90.4 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "9rKjoTAv0eg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8b08a0aa-831b-4b88-8dee-9af9a28685ae"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "c4qmDdpf0eg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "qikiqzvo0eg-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "i_GLF-B_0ehA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "16c72b0e-169c-4a45-c447-ac7b8a72e8fc"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "zZnYHnOr0ehC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "c034ae5e-ed0c-4ff2-d042-df7b9bc220c2"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LAYi8EVy0ehJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "5jwofs2a0ehK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "747306aa-88fc-4326-b01c-f47d29460166"
      },
      "cell_type": "code",
      "source": [
        "tokens = set()### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "for na in names:\n",
        "    for c in na:\n",
        "        tokens.add(c)\n",
        "tokens = list(tokens)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JkF_nhLu2-P8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1007
        },
        "outputId": "d1d91fca-02a6-469e-8999-d4c2b02aaa4b"
      },
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['s',\n",
              " 'g',\n",
              " 'V',\n",
              " 'j',\n",
              " 'z',\n",
              " 'D',\n",
              " 'F',\n",
              " 't',\n",
              " 'r',\n",
              " 'k',\n",
              " \"'\",\n",
              " 'f',\n",
              " 'C',\n",
              " 'H',\n",
              " 'a',\n",
              " 'e',\n",
              " 'm',\n",
              " 'M',\n",
              " 'B',\n",
              " 'l',\n",
              " 'R',\n",
              " 'v',\n",
              " 'o',\n",
              " 'E',\n",
              " 'b',\n",
              " 'W',\n",
              " 'P',\n",
              " 'S',\n",
              " 'X',\n",
              " 'p',\n",
              " 'c',\n",
              " 'I',\n",
              " 'd',\n",
              " 'T',\n",
              " 'w',\n",
              " '-',\n",
              " ' ',\n",
              " 'N',\n",
              " 'x',\n",
              " 'u',\n",
              " 'q',\n",
              " 'L',\n",
              " 'J',\n",
              " 'A',\n",
              " 'K',\n",
              " 'y',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'Q',\n",
              " 'n',\n",
              " 'U',\n",
              " 'i',\n",
              " 'G',\n",
              " 'h',\n",
              " 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "PV1yg4Mt0ehN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "VQAbwQw80ehO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = {key:value for value,key in enumerate(tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "t_rcr4k50ehS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "qJ3H80iJ0ehW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "ce599e1a-370e-4e5f-f338-1cbae5da838a"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[36 43 24 14  1 14 15 19  0]\n",
            " [36 52 19 22  8 45  0  0  0]\n",
            " [36 26  8 51  0  0 51 15  0]\n",
            " [36 52 51 22 21 14 49 49 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZLDWOVC0ehc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "9xSeFbsA0ehc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "RKlxT2JD0ehh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units,activation='tanh')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens,activation='softmax')### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "llm9lYJy0ehj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "OYZrPH8E0ehk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = Concatenate()([x_t_emb,h_t])### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJq-TTmQ0eh-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "YDkkuWOa0eiL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BcP8JYP80eiX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "D-xoB1oZ0eiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItS2qfKZ0eia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "UGlij8zm0eib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f77d2ebc-efed-4579-c220-d94a3dfe4165"
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix*tf.log(predictions_matrix))### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N2MwtHmQ0eie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "8jTBYfrT0eie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1057dc84-dbc9-4571-ffb0-cd75381c8dd4"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_qBzPSop0eii",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "g5_qYZBC0eij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "zLySe25s0eio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "eKITqgBR0eiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f56bd413-7bd6-4e68-8451-915061c8f478"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Marsmesssssssss\n",
            " Zianlinssssssss\n",
            " Ranyciadsssssss\n",
            " Jivetlessssssss\n",
            " Giareesssssssss\n",
            " Serillsssssssss\n",
            " Bulnyssssssssss\n",
            " Masssssssssssss\n",
            " rabanesssssssss\n",
            " Ssbihusssssssss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "RK5-AVD70eit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c55095bd-9536-48cf-bcf8-f46038bed974"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumposssssssss\n",
            " Trumpesssssssss\n",
            " Trumponinssssss\n",
            " Trumpigssssssss\n",
            " Trumptsssssssss\n",
            " Trumpanssssssss\n",
            " Trumpanssssssss\n",
            " Trumpirssssssss\n",
            " Trumpilssssssss\n",
            " Trumphessssssss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TPrLBLCR0eiv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "8UEiru5Y0eiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"lUbUGxtTy2MOc3Uv\"### YOUR TOKEN HERE ###\n",
        "COURSERA_EMAIL = \"hktxt2011@gmail.com\"### YOUR EMAIL HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "W4D09Y540eiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9139daa2-7ed9-4326-a0ef-d0c5b6139276"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XOrzRLMC0ei1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "rPKyRTDJ0ei2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "NIhtYmP-0ei2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bf601a6a-42ac-47b7-98cc-79f30bc43d74"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-34-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-34-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "plj_sInB0ei4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "hU-4LVjy0ei5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5b7294ab-d1a4-44d5-e622-dccb09ca4f91"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "veXDHNNG0ei7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "602afe33-889e-44fe-bc62-9b4d7b5440f9"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-36-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}